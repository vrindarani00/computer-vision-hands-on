{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (5708, 200, 200, 3) (5708,)\n",
      "Training data shape: (4566, 200, 200, 3) (4566,)\n",
      "Validation data shape: (1142, 200, 200, 3) (1142,)\n",
      "Train descriptors: 3861\n",
      "Train labels: 3861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vrinda\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histograms: 3861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vrinda\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation descriptors: 969\n",
      "Validation labels: 969\n",
      "Validation histograms: 969\n",
      "Validation accuracy: 30.753353973168213\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = r'C:\\Users\\vrinda\\Documents\\GitHub\\computer-vision-hands-on\\Problem\\dataset\\wood_species_train.hdF5'\n",
    "\n",
    "# Load data from the HDF5 file\n",
    "# Load data from the HDF5 file\n",
    "with h5py.File(train_data, 'r') as f:\n",
    "    imgs = f['images'][:]\n",
    "    labels = f['labels'][:]\n",
    "\n",
    "print(\"Data shape:\", imgs.shape, labels.shape)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "trainX, valX, trainY, valY = train_test_split(imgs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data shape:\", trainX.shape, trainY.shape)\n",
    "print(\"Validation data shape:\", valX.shape, valY.shape)\n",
    "\n",
    "# Initialize ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Extract descriptors and labels for training set\n",
    "trainX_descriptors = []\n",
    "trainY_desc = []\n",
    "\n",
    "for i, img in enumerate(trainX):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    key, desc = orb.detectAndCompute(image, None)\n",
    "    if desc is not None:\n",
    "        trainX_descriptors.append(desc)\n",
    "        trainY_desc.append(trainY[i])\n",
    "\n",
    "print(\"Train descriptors:\", len(trainX_descriptors))\n",
    "print(\"Train labels:\", len(trainY_desc))\n",
    "\n",
    "# Perform k-means clustering on training descriptors\n",
    "fitX_descriptors = np.vstack(trainX_descriptors)\n",
    "kmeans = KMeans(n_clusters=10, init='k-means++')\n",
    "kmeans.fit(fitX_descriptors)\n",
    "\n",
    "# Generate histograms for training set\n",
    "hist_list = []\n",
    "for descriptors in trainX_descriptors:\n",
    "    pred = kmeans.predict(descriptors)\n",
    "    histogram, _ = np.histogram(pred, bins=10)\n",
    "    hist_list.append(histogram)\n",
    "\n",
    "print(\"Histograms:\", len(hist_list))\n",
    "\n",
    "# Train SVM classifier\n",
    "clf = LinearSVC(max_iter=200000)\n",
    "clf.fit(hist_list, trainY_desc)\n",
    "\n",
    "# Extract descriptors and labels for validation set\n",
    "valX_descriptors = []\n",
    "valY_desc = []\n",
    "\n",
    "for i, img in enumerate(valX):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    key, desc = orb.detectAndCompute(image, None)\n",
    "    if desc is not None:\n",
    "        valX_descriptors.append(desc)\n",
    "        valY_desc.append(valY[i])\n",
    "\n",
    "print(\"Validation descriptors:\", len(valX_descriptors))\n",
    "print(\"Validation labels:\", len(valY_desc))\n",
    "\n",
    "# Generate histograms for validation set\n",
    "val_hist_list = []\n",
    "for descriptors in valX_descriptors:\n",
    "    pred = kmeans.predict(descriptors)\n",
    "    histogram, _ = np.histogram(pred, bins=10)\n",
    "    val_hist_list.append(histogram)\n",
    "\n",
    "print(\"Validation histograms:\", len(val_hist_list))\n",
    "\n",
    "# Predict labels for validation set using the trained classifier\n",
    "val_predictions = clf.predict(val_hist_list)\n",
    "\n",
    "# Calculate accuracy for validation set\n",
    "val_accuracy = accuracy_score(valY_desc, val_predictions)\n",
    "print(\"Validation accuracy:\", val_accuracy * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

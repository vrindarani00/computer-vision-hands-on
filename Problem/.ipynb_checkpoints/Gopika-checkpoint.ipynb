{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading images\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.pyplot import scatter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image and extract SIFT keypoints and descriptors\n",
    "img = cv2.imread('image.jpg')\n",
    "\n",
    "\n",
    "folder_dir = r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\1\"\n",
    "sift = cv2.SIFT_create(nfeatures = 100,contrastThreshold=0.01, edgeThreshold=10)\n",
    "c = 0\n",
    "des = []\n",
    "for image_name in os.listdir(folder_dir):\n",
    "    image_path = os.path.join(folder_dir, image_name)\n",
    "#     c+=1\n",
    "#     if c>=100:\n",
    "#         break\n",
    "    if image_name.endswith(\".png\") or image_name.endswith(\".jpg\"):\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)       \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
    "        \n",
    "        k,d = sift.detectAndCompute(image,None)\n",
    "        des.append(d)\n",
    "#         print(np.array(k).shape)\n",
    "#         print(d.shape)\n",
    "#         print(c)\n",
    "len(des)\n",
    "# print(des.shape)\n",
    "# print(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = np.vstack(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93757, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "K = 100\n",
    "kmeans = KMeans(n_clusters=K)\n",
    "kmeans.fit(di)\n",
    "\n",
    "# Get the cluster labels\n",
    "labels = kmeans.predict(di)\n",
    "\n",
    "# Get the cluster centers\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# # Plot the clusters\n",
    "# colors = ['r', 'g', 'b', 'c', 'm']\n",
    "# for i in range(K):\n",
    "#     cluster = des[labels == i]\n",
    "#     plt.scatter(cluster[:, 0], cluster[:, 1], c=colors[i], s=10, alpha=0.5)\n",
    "\n",
    "# # Plot the centroids\n",
    "# #         plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=150, linewidths=3, color='k', zorder=10)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 128)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(di[2].reshape(1,-1))\n",
    "# print(d[67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths to the folders containing the images\n",
    "folder_paths = [\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\1\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\2\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\3\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\4\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\5\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\6\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\7\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\8\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\9\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\10\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\11\",\n",
    "    r\"C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\dataset\\Train\\12\"\n",
    "    # Add the paths to the other folders here\n",
    "]\n",
    "\n",
    "# Define the output HDF5 file\n",
    "output_file = \"output.hdf5\"\n",
    "\n",
    "# Define the maximum number of images to read from each folder\n",
    "max_images_per_folder = 1000\n",
    "\n",
    "# Open the output file in write mode\n",
    "with h5py.File(output_file, \"w\") as f:\n",
    "\n",
    "    # Create a group for each folder\n",
    "    for folder_path in folder_paths:\n",
    "        group_name = os.path.basename(folder_path)\n",
    "        group = f.create_group(group_name)\n",
    "\n",
    "        # Iterate over the images in the folder\n",
    "        for i, image_file in enumerate(os.listdir(folder_path)):\n",
    "            if i >= max_images_per_folder:\n",
    "                break\n",
    "\n",
    "            # Read the image file\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Convert the image to grayscale and resize it to (256, 256)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (256, 256))\n",
    "\n",
    "            # Add the image to the HDF5 file\n",
    "            dataset_name = f\"{group_name}/{image_file}\"\n",
    "            dataset = group.create_dataset(dataset_name, data=image)\n",
    "\n",
    "    # Add an attribute to the file indicating the number of images per folder\n",
    "    f.attrs[\"max_images_per_folder\"] = max_images_per_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = r'C:\\Users\\G\\DUK\\CV_PROJ\\github\\computer-vision-hands-on\\Problem\\output.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.zeros((100,128))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # # Load the HDF5 file\n",
    "# # with h5py.File('output.hdf5', 'r') as f:\n",
    "# #     dataset = f['di']\n",
    "\n",
    "# #     # Iterate through the dataset to extract the SIFT descriptors for each image\n",
    "# #     descriptors = []\n",
    "# #     for image in dataset:\n",
    "# #         descriptors.append(image)\n",
    "\n",
    "#     # Compute the histograms for each image\n",
    "# histograms = []\n",
    "# for desc in di:\n",
    "#     hist, bins = np.histogram(desc, bins=128, range=(0, 255))  # You may need to adjust the number of bins and range to fit your data\n",
    "#     histograms.append(hist)\n",
    "\n",
    "# # Combine the histograms for all the images\n",
    "# final_hist = np.sum(histograms, axis=0)\n",
    "\n",
    "# # Plot the final histogram\n",
    "# plt.bar(bins[:-1], final_hist, width=np.diff(bins))\n",
    "# plt.xlabel('SIFT Descriptor Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'calcHist'\n> Overload resolution failed:\n>  - Can't parse 'images'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'images'. Sequence item with index 0 has a wrong type\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m image_data \u001b[38;5;241m=\u001b[39m dataset[i]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Compute the histogram using OpenCV\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalcHist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m hist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(hist)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Append the histogram to the list\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'calcHist'\n> Overload resolution failed:\n>  - Can't parse 'images'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'images'. Sequence item with index 0 has a wrong type\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File('output.hdf5', 'r') as file:\n",
    "    # Access the image dataset\n",
    "    dataset = dataset_name\n",
    "\n",
    "    # Create a list to store the histograms\n",
    "    histograms = []\n",
    "\n",
    "    # Loop through each image in the dataset\n",
    "    for i in range(len(dataset)):\n",
    "        # Read the image data into a NumPy array\n",
    "        image_data = dataset[i]\n",
    "\n",
    "        # Compute the histogram using OpenCV\n",
    "        hist = cv2.calcHist([image_data], [0], None, [256], [0, 256])\n",
    "        hist = np.ravel(hist)\n",
    "\n",
    "        # Append the histogram to the list\n",
    "        histograms.append(hist)\n",
    "\n",
    "# Convert the list of histograms to a NumPy array\n",
    "histograms = np.array(histograms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('output.hdf5', 'r') as file:\n",
    "    # List all the datasets in the file\n",
    "    dataset_name = []\n",
    "    for q in file.keys():\n",
    "        dataset_name.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

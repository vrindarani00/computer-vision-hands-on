{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\vrinda\\Desktop\\2nd sem\\CV\\dtest.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  scale factor\n",
    "scale_factor = .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the image\n",
    "scaled_img = cv2.resize(img, (int(scale_factor*img.shape[1]),int(scale_factor*img.shape[0])), interpolation=cv2.INTER_LINEAR)\n",
    "cv2.imshow('Org',img)\n",
    "cv2.imshow('Scaled',scaled_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SIFT detector\n",
    "sift = cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the  keypoints and computing descriptors\n",
    "key_1, des1 = sift.detectAndCompute(img, None)\n",
    "key_2, des2 = sift.detectAndCompute(scaled_img, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BFMatcher with default params\n",
    "bf = cv2.BFMatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match descriptors\n",
    "matches = bf.knnMatch(des1, des2, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ratio test\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.50 * n.distance:\n",
    "        good.append(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing  matches\n",
    "final_img = cv2.drawMatches(img, key_1, scaled_img, key_2, good, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imshow('Matching Result', final_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rotaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  rotation angle in degrees\n",
    "angle = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rotation matrix\n",
    "rotation_matrix = cv2.getRotationMatrix2D((img.shape[1]/2, img.shape[0]/2), angle, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rotation to image\n",
    "rotated= cv2.warpAffine(img, rotation_matrix, (img.shape[1], img.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SIFT keypoints and descriptors from original and rotated images\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(img, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(rotated, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display original and rotated images with keypoints\n",
    "img_with_keypoints1 = cv2.drawKeypoints(img, keypoints1, None)\n",
    "img_with_keypoints2 = cv2.drawKeypoints(rotated, keypoints2, None)\n",
    "cv2.imshow(\"Original Image with Keypoints\", img_with_keypoints1)\n",
    "cv2.imshow(\"Rotated Image with Keypoints\", img_with_keypoints2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## affine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find keypoints and descriptors\n",
    "key, d = sift.detectAndCompute(img, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the affine transformation matrix\n",
    "theta = np.radians(50)\n",
    "scale = 1.0\n",
    "tx, ty = 100, -50\n",
    "\n",
    "M = np.array([\n",
    "    [scale * np.cos(theta), -scale * np.sin(theta), tx],\n",
    "    [scale * np.sin(theta), scale * np.cos(theta), ty]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the affine transformation\n",
    "img_affine = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find keypoints and descriptors in the transformed image\n",
    "kp_affine, des_affine = sift.detectAndCompute(img_affine, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw keypoints on the images\n",
    "img_kp = cv2.drawKeypoints(img, key, None)\n",
    "img_affine_sift = cv2.drawKeypoints(img_affine, kp_affine, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the images\n",
    "cv2.imshow('Original', img_kp)\n",
    "cv2.imshow('Affine Transformation', img_affine_sift)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the four corners of the original image\n",
    "pts1 = np.float32([[0, 260], [0, img.shape[0]-1], [img.shape[1]-1, img.shape[0]-1], [img.shape[1]-1, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the four corners of the desired output image\n",
    "pts2 = np.float32([[0, 0], [0, 400], [400, 400], [400, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the perspective transform matrix\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the perspective transform to the original image\n",
    "perspective_img = cv2.warpPerspective(img, M, (400, 400))\n",
    "# cv2.imshow('Perspective',perspective_img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SIFT keypoints and descriptors from original and transformed images\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(img, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(perspective_img, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a brute-force matcher to find matches between descriptors\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.match(descriptors1, descriptors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw matching lines on a new image\n",
    "# Drawing  matches\n",
    "final_img = cv2.drawMatches(img, keypoints1, perspective_img, keypoints2, matches[:20], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image with matching lines\n",
    "cv2.imshow(\"Matches\", final_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
